---
title: Slower by Half
subtitle: One Overlooked Aspect of how AI Impacts Social Growth
created: 2025-06-01
edited: 2025-06-01
tags: ['AI', 'Hot Takes']
---

<p class=“indented”>There are two large parts of reality which our current economic system has a lot of trouble representing. One big one is power. Modern economics thinks that a person who is looking to purchase something like healthcare coverage is in a position to gather all pertinent information, assess it, and make a rational decision, and that there is not a massive power imbalance that the healthcare company's capital affords it in terms of skewing the outcome of the interaction in their favor.</p>

<p class="indented">Another thing that our economic methodology handles very poorly is externalities. For instance, A company buys a forest. They clear cut it for lumber and sell the lumber. Our economic system would look at that and say that this is the end of the story. The company had an asset and made a decision on what to do with it. They transformed that beginning asset (forested land) into another one (lumber), which has a monetary value which was higher than the forested land was to them, and they can now receive the extra value which they have created by cutting the trees down.</p>

<p class="indented">Maybe, if the government is very progressive my modern standards, the government might step in and say something like "Hey, this forest captured a significant amount of carbon, which it no longer does now that you cut it down. From the profit you made by cutting the forest down, we're going to make you also pay money to remediate this difference in freed carbon." In this instance, the carbon issue was an externality, which an external regulatory body is forcing them to internalize.</p>

<p class="indented">However, which externalities are we going to regulate, or even recognize is tenuous at best. Besides carbon, what about the role the forest played in the water cycle? Nitrogen cycle?  What about the value of the animals who depended on that forest for a habitat? What role did it play in facilitating propagation in surrounding flora? What role did that forest play in the territoriality of the fauna? What impact will the clear cutting have on local erosion, and the change in soil quality, both mineral and organic?</p>

<p class="indented">At this point, any economist will likely roll their eyes. After all, just the carbon study already caused years of delay in the project. You want to get more bureaucrats in here? Then the project will never happen!</p>

<p class="indented">And to a great extent, this is true. I'm not saying this is necessarily wrong, but merely to point out that for our modern economic system to work, especially a capitalistic one, externalities have to remain externalities.</p>

<p class="indented">It is not at all surprising that when we look at the ways people are struggling to adapt to AI, many of them come from failures to understand power and externalities.</p>

<h3>Unseen Externalities</h3>

<p class="indented">One externality that I've been fascinated with that has been massively impacted by the development and adoption of AI is the elimination of an externality I haven't really heard anyone discuss. Take the example of a book. Before the proliferation of generative AI, if someone wanted to write a book, that means that someone had to write it. Society, as a whole, got a double benefit from that transaction. Not only did the consumer get a book they purchased, value was also generated by the author undertaking the endeavor of writing the book. They sat down and were compensated for the intellectual development necessary to write that book. Not only is the writer now a more experienced writer, there may have been research or other valuable content generated as well. Society got a double benefit from that transaction.</p>

<p class="indented">Of course, to the consumer, the presumptive totally rational decisionmaker in this situation, the writer's professional development was an externality that they didn't have to account for. In fact, it's almost a point of distain. A writer who already has written many, many books will likely benefit less from the experience than an author who has written fewer books. So if the consumer wanted to maximize that specific externality, they might even want to prefer purchasing the book from the less experienced writer over the more experienced one, even if it leads to a lesser product.</p>

<p class="indented">The point is that up until now, every productive economic transaction has had this double effect. For a house to be built, someone had to be or become a good enough builder to build it. For a book to be written, someone had to be or become a good enough writer to write it. For software to be written, someone had to be or become a good enough dev to write it.</p>

<p class="indented">I am not saying that this is has always been good. For instance, a movie I liked was <em>Hidden Figures</em> (2016), where black women employed in a "computing group", and basically used to slog through the grunt work of doing the menial mathematical calculations required to run a space program. (The point of the movie being to highlight the massive contribution that these women made to the program, despite historic lack of representation.) One of the calculators, Dorothy Vaughn, reads the tea leaves when it comes to computing technology, and learns how to use one of the huge, new mainframe computers that NASA had just gotten. By teaching other women in the group how to use these computers, she keeps the unit and keeps all these women employed by teaching them how to work with computers as well.</p>

<p class="indented">If NASA is the consumer in this situation of computing needs, I don't think anyone would say that because of their increase in skill in doing mathematical calculations, NASA shouldn't have used a computer. However, we should recognize what Dorothy Vaughn did, which is that instead of investing in the skill of doing mental and manual mathematical calculations, they should invest in the skill of working with computers.</p>

<p class="indented">Since silicon computers can do calculations at much higher speed and accuracy than human calculators can, this switch made sense and continues to make sense. But this isn't always the case. For instance, the art of tailoring clothes was massively impacted by the introduction of the sewing machine. These machines could have been tools in the hands of skilled craftsman to increase their quality and productivity, but instead owners of textile companies decided to use it as an opportunity to slash their workforce of skilled tailors in favor of lower-skilled and therefore lower-paid workers to make clothes that were "good enough", leading to the sort of average clothing quality and overconsumption that we have today. (See Brian Merchant's book <em>Blood In The Machine</em>.)</p>

<p class="indented">In this instance, the externality of the business decision by those textile company owners was that a lot of skills and expertise was no longer being invested in. And it's a skill that's still in demand today. Instead of clothes that fit better and last longer, we have TEMU and Shein.</p>

<p class="indented">My point is that changes in these externalities aren't necessarily bad, but they certainly can be. So what impact is generative AI having on society? The truest answer is that I don't know, at least not in a comprehensive sense. What I do want to share, however, is the changes that I see.</p>

<p class="indented">I teach a one credit pass/fail class on legal research for law students. In that context, students are both the consumer and the supplier of that research activity. I give them an assignment that requires them to find something, and they have to either have or acquire the skills required to find it. The overt goal of the course is not that they know where to find any piece of research material, but that they become better researchers.</p>

<p class="indented">Instead of building a mental map and understanding of different resources and how to access them, students can just use a generative AI tool to get to an answer instead. Because even RAG architectures aren't perfect when it comes to retrieving and analyzing sources, students are no longer equipped to double check and verify the answers given by these AI tools if they rely on the tools to an extent to where they they are not sufficiently good researchers.</p>

<p class="indented">A large portion of my assignments also require an amount of writing. Traditionally, students in my graduate program must have been strong writers because of field they are training to enter. Here, I think that the externalities of LLMs are actually closer to neutral. I don't think any of my students just copy and paste and answer from an LLM into the assignment without verification. However, the students I have now had go through undergrad without LLM tools. I've heard stories from other instructors about how some students will not even spend half an hour on an essay, relying purely on LLMs to generate essays and other assignments. Maybe when those students get to my program, I'll truly have students who don't know how to write. In that instance, I think the continued use of LLMs to fill out assignments would have a much worse effect. If students already know how to read and write effectively, then using these tools can't really harm them. If they don't, however, it robs them of the opportunities they need to develop them.</p>

<p class="indented">The big question that a lot of people ask a this point is "so what?" Technology always moves forward, so if we lose these skills, is it really that bad? I think that question is difficult to quantify. I honestly think so. Despite its perceived creativity, all neural nets do is encode patterns that exist in its training data. This means that even working at perfect accuracy, the only responses it can possibly offer are the responses found in the training data's patterns. In this way, it's literally conservative, i.e. conserving the things that came before it. In the practice of law this is not necessarily a good thing. Superficially, law in the US claims the principle of Stare Decisis, or precedent, where the outcome of prior cases binds the outcome of later cases, but there are new and emergent situations all the time, which the law has not encountered. The decision to bind the current case to a former one is an ahistorical decision that needs to be made in every instance. The law also has an overt history of de jure and de facto injustices, which technologies like this risk preserving.</p>

<p class="indented">This is not to even mention what might happen with arts. The role of art and the artist is to look deeply at life, and do the time and effort to examine insights into the human experience and society. There are undoubtedly many people who have been doing that sort of work who are no longer going to, either because they aren't able to from a practical standpoint, or don't want their work to be ingested into a model.</p>

<h3>What I think will happen</h3>

<p class="indented">Human progress will change, and in some ways, slow. We have been getting a double effect of gaining both the thing made and the maker in society. However, this effect is going to be diminished to a great extent. This might free people up to do different things and steer human creativity and productivity in different ways, but maybe not.</p>

<p class="indented">Note that these effects will also be a while in the making, probably not to be realized until a significant portion of the working population is replaced. There will be people who produce writing who do not themselves know how to write. People will produce code who do not really know how to code. People who do not know how to make digital art are going to tomorrow's artists. We don't understand what happens when these human skills and actives are lost.</p>

<p class="indented">There's a common complaint from people who oppose how corporations are using AI, that it's that AI is being used to replace creative things like making music and drawing while humans are stuck doing menial jobs. It should be the other way around, where AI is used to replace the menial stuff while humans can engage in creative pursuits. However, we know that that probably isn't going to happen.</p>